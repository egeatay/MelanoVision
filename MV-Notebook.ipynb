{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# MelanoVision\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to pedrocast7 for the EDA starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T21:18:00.830295Z",
     "iopub.status.busy": "2024-07-04T21:18:00.829982Z",
     "iopub.status.idle": "2024-07-04T21:18:00.843827Z",
     "shell.execute_reply": "2024-07-04T21:18:00.842942Z",
     "shell.execute_reply.started": "2024-07-04T21:18:00.830270Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import numpy.matlib\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import random\n",
    "import os ## handle files\n",
    "import torch ## PyTorch\n",
    "import torch.nn as nn ## Neural networks package\n",
    "from torch import optim ## optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchvision import models ## package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, TensorDataset\n",
    "import torchvision.transforms as transforms ## for data augmentation\n",
    "from sklearn.model_selection import train_test_split ## to split datasets\n",
    "import seaborn as sns ## data plot\n",
    "from sklearn.metrics import confusion_matrix ## plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the random seed for reproducibility\n",
    "seed = 77\n",
    "np.random.seed(seed) ## for numpy\n",
    "torch.manual_seed(seed) ## for PyTorch\n",
    "torch.cuda.manual_seed(seed)\n",
    "random.seed(24) ## for random module on python\n",
    "\n",
    "\n",
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "    \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") ## use gpu if its available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T21:19:11.873944Z",
     "iopub.status.busy": "2024-07-04T21:19:11.873567Z",
     "iopub.status.idle": "2024-07-04T21:19:12.048919Z",
     "shell.execute_reply": "2024-07-04T21:19:12.048052Z",
     "shell.execute_reply.started": "2024-07-04T21:19:11.873915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Path to data\n",
    "HAM1000_path = r'C:\\Users\\ege\\git\\MelanoVision\\ham1'\n",
    "\n",
    "## to map the class acronym to its real name, according to the paper of the dataset\n",
    "lesion_type_dict = {\n",
    "    'nv': 'Melanocytic nevi',\n",
    "    'mel': 'Melanoma',\n",
    "    'bkl': 'Benign keratosis-like lesions ',\n",
    "    'bcc': 'Basal cell carcinoma',\n",
    "    'akiec': 'Actinic keratoses',\n",
    "    'vasc': 'Vascular lesions',\n",
    "    'df': 'Dermatofibroma'\n",
    "}\n",
    "\n",
    "## collecting image paths\n",
    "all_image_path = glob(os.path.join(HAM1000_path, '*', '*.jpg'))\n",
    "\n",
    "## imageid_path_dict will map each image ID (the file name without the extension) to its full file path.\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}\n",
    "\n",
    "\n",
    "df_original = pd.read_csv(os.path.join(HAM1000_path, 'HAM10000_metadata.csv'))\n",
    "df_original['path'] = df_original['image_id'].map(imageid_path_dict.get)\n",
    "df_original['cell_type'] = df_original['dx'].map(lesion_type_dict.get)\n",
    "df_original['cell_type_idx'] = pd.Categorical(df_original['cell_type']).codes\n",
    "\n",
    "## class names\n",
    "classes = df_original['dx'].unique()\n",
    "\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T21:19:14.339383Z",
     "iopub.status.busy": "2024-07-04T21:19:14.338395Z",
     "iopub.status.idle": "2024-07-04T21:19:14.749232Z",
     "shell.execute_reply": "2024-07-04T21:19:14.748379Z",
     "shell.execute_reply.started": "2024-07-04T21:19:14.339351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count the number of images in each class\n",
    "class_counts = df_original['cell_type'].value_counts()\n",
    "\n",
    "# Plot a histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts.plot(kind='barh')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Number of Images per Class')\n",
    "plt.ylabel('Class')\n",
    "plt.xlabel('Number of Images')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T03:22:00.395404Z",
     "iopub.status.busy": "2024-07-04T03:22:00.394532Z",
     "iopub.status.idle": "2024-07-04T03:22:04.114359Z",
     "shell.execute_reply": "2024-07-04T03:22:04.112935Z",
     "shell.execute_reply.started": "2024-07-04T03:22:00.395371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Showing some examples of the data\n",
    "\n",
    "# Randomly select 15 rows from the dataframe\n",
    "sample_df = df_original.sample(n=15)\n",
    "\n",
    "# Set up the matplotlib figure and axes\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, (_, row) in zip(axes, sample_df.iterrows()):\n",
    "    img_path = row['path']\n",
    "    cell_type = row['cell_type']\n",
    "    \n",
    "    # Open the image\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Display the image on the axis\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(cell_type)\n",
    "    ax.axis('off')  # Hide the axes ticks\n",
    "\n",
    "# Add a main title for the whole plot\n",
    "plt.suptitle('HAM10000 Examples', fontsize=20)\n",
    "# Adjust the layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T21:19:19.723786Z",
     "iopub.status.busy": "2024-07-04T21:19:19.722707Z",
     "iopub.status.idle": "2024-07-04T21:19:19.747739Z",
     "shell.execute_reply": "2024-07-04T21:19:19.746700Z",
     "shell.execute_reply.started": "2024-07-04T21:19:19.723745Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Plots the Train/Val curves (Losses and Main Metric) \n",
    "def plot_history(train_loss_hist, val_loss_hist, train_acc_hist, val_acc_hist, model_name):\n",
    "    epochs = range(1, len(train_loss_hist) + 1)\n",
    "    \n",
    "    # Plotting the loss history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss_hist, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss_hist, 'ro-', label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Loss: {model_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc_hist, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc_hist, 'ro-', label='Validation Accuracy')\n",
    "    plt.title(f'Training and Validation Balanced Accuracy: {model_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Balanced Accuracy')\n",
    "    plt.ylim(0.4, 1)  # Set y-axis limit from 0.4 to 1\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "## Plots the confusion matrix given a prediction and target labels\n",
    "def plot_confusion_matrix(all_predictions, all_labels, num_classes, model_name):\n",
    "    '''Plot the confusion matrix using predictions and true labels'''\n",
    "    cm = confusion_matrix(all_labels.cpu().numpy(), all_predictions.cpu().numpy())\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='inferno', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "## gets the mean and std from a given dataset\n",
    "def compute_img_mean_std(image_paths):\n",
    "    \"\"\"\n",
    "        computing the mean and std of three channel on the whole dataset,\n",
    "        first we should normalize the image from 0-255 to 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    img_h, img_w = 120, 120\n",
    "    imgs = []\n",
    "    means, stdevs = [], []\n",
    "\n",
    "    for i in tqdm(range(len(image_paths))):\n",
    "        img = cv2.imread(image_paths[i])\n",
    "        img = cv2.resize(img, (img_h, img_w))\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.stack(imgs, axis=3)\n",
    "    print(imgs.shape)\n",
    "\n",
    "    imgs = imgs.astype(np.float32) / 255.\n",
    "\n",
    "    for i in range(3):\n",
    "        pixels = imgs[:, :, i, :].ravel()  # resize to one row\n",
    "        means.append(np.mean(pixels))\n",
    "        stdevs.append(np.std(pixels))\n",
    "\n",
    "    means.reverse()  # BGR --> RGB\n",
    "    stdevs.reverse()\n",
    "\n",
    "    print(\"normMean = {}\".format(means))\n",
    "    print(\"normStd = {}\".format(stdevs))\n",
    "    return means,stdevs\n",
    "\n",
    "## Define the custom dataset class\n",
    "class CustomHAM10000(Dataset):\n",
    "    def __init__(self, dataframe, img_size, transform=None):\n",
    "        self.paths = dataframe['path'].values\n",
    "        self.labels = torch.tensor(dataframe['cell_type_idx'].values, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.paths[idx]\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import timm  # Library to provide transformer models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for ViT\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Use train_test_split to split the dataset into train and test\n",
    "train_df, test_df = train_test_split(df_original, test_size=0.2, random_state=42, stratify=df_original['cell_type_idx'])\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = CustomHAM10000(train_df, img_size=(224, 224), transform=transform)\n",
    "test_dataset = CustomHAM10000(test_df, img_size=(224, 224), transform=transform)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "model.head = nn.Linear(model.head.in_features, len(classes))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct_predictions = 0\n",
    "    for inputs, labels in tqdm(data_loader, desc='Training'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = correct_predictions.double() / len(data_loader.dataset)\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc='Evaluating'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(data_loader.dataset)\n",
    "    epoch_acc = correct_predictions.double() / len(data_loader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "model1.head = nn.Linear(model1.head.in_features, len(classes))  # Adjust the final layer to match number of classes\n",
    "optimizer1 = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "\n",
    "for k, v in model1.named_parameters():\n",
    "    v.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "#summary(model1, input_size=(3, 224, 224))\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_details(model):\n",
    "    print(\"Layer Name\".ljust(30), \"Output Shape\".ljust(30), \"Param #\")\n",
    "    print(\"=\"*60)\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            layer_params = param.numel()\n",
    "            total_params += layer_params\n",
    "            print(f\"{name}\".ljust(30), str(param.shape).ljust(30), layer_params)\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "model_details(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model1.named_parameters():\n",
    "    print(k)\n",
    "    #print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "\n",
    "optimizerx = optim.AdamW(filter(lambda p: p.requires_grad, modelx.parameters()), lr=0.0001)\n",
    "\n",
    "trainable = sum([v.numel() for _,v in model1.named_parameters() if v.requires_grad])\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable:,}\")\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 15)\n",
    "    print('-' * 15)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(modelx, train_loader, criterion, optimizerx, device)\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    \n",
    "    test_loss, test_acc = evaluate(modelx, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = sum([v.numel() for _,v in model1.named_parameters() if v.requires_grad])\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable:,}\")\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 15)\n",
    "    print('-' * 15)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model1, train_loader, criterion, optimizer1, device)\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    \n",
    "    test_loss, test_acc = evaluate(model1, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "model2.head = nn.Linear(model2.head.in_features, len(classes))  # Adjust the final layer to match number of classes\n",
    "optimizer2 = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "\n",
    "for k, v in model2.named_parameters():\n",
    "    #print(k, str(v.requires_grad)[0], \"-> \", end=''   )#, v)\n",
    "    if (k[:7]==\"blocks.\"):\n",
    "        v.requires_grad = (\"bias\" in k)\n",
    "    #print(str(v.requires_grad)[0])\n",
    "    #v.requires_grad = v.requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = sum([v.numel() for _,v in model2.named_parameters() if v.requires_grad])\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable:,}\")\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 15)\n",
    "    print('-' * 15)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model2, train_loader, criterion, optimizer2, device)\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    \n",
    "    test_loss, test_acc = evaluate(model2, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = timm.create_model('vit_base_patch16_224', pretrained=True).to(device)\n",
    "model3.head = nn.Linear(model3.head.in_features, len(classes))  # Adjust the final layer to match number of classes\n",
    "optimizer3 = optim.Adam(model3.parameters(), lr=0.0001)\n",
    "\n",
    "for k, v in model3.named_parameters():\n",
    "    #print(k, str(v.requires_grad)[0], \"-> \", end=''   )#, v)\n",
    "    if (k[:7]==\"blocks.\"):\n",
    "        v.requires_grad = (\"bias\" in k)\n",
    "    #print(str(v.requires_grad)[0])\n",
    "    #v.requires_grad = v.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = sum([v.numel() for _,v in model3.named_parameters() if v.requires_grad])\n",
    "\n",
    "print(f\"Trainable Parameters: {trainable:,}\")\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 15)\n",
    "    print('-' * 15)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model3, train_loader, criterion, optimizer3, device)\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "    \n",
    "    test_loss, test_acc = evaluate(model3, test_loader, criterion, device)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5275642,
     "sourceId": 8777560,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
